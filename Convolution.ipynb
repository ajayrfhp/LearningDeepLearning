{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOeXzafQYfUXSXhowROYO0F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajayrfhp/LearningDeepLearning/blob/main/Convolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwTwniMR_J4P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conv net\n",
        "- Images have rich spatial structure. FLattening an image and building MLPs is waste of parameters. An image with million pixels could need million parameters\n",
        "- Objects in images can be present anywhere in an image. We can slide a patch detector across image, get activation and use it to see object is present in the image.\n",
        "- Earlier regions detect local patches, later regions detect higher level activations\n",
        "- By parameter sharing, that is, sharing a conv kernel across an image, we can greatly decrease number of parameters of the network\n",
        "- Mechanics\n",
        "  \n",
        "  ```\n",
        "  delta = k / 2\n",
        "  for l in (-delta, delta):\n",
        "    for m in (-delta, delta):\n",
        "      h[i, j] = w[l][m] * x[i+l][j+m]\n",
        "  ```\n",
        "- Params\n",
        "  - Params in one conv filter = $k*k + 1$\n",
        "  - Params in n conv filters = $n * (k*k + 1)$\n",
        "  - You would need a 3d conv filter if input has multiple color channels called c\n",
        "  - Params in n conv filters operating over c channels = $n * c * (k*k + 1)$\n",
        "- If k = 0, then you have one weight param per pixel, channel. This leads to network in network architectures.\n",
        "\n",
        "- Shape of output without padding is (w-k+1,h-k+1)\n",
        "\n",
        "- Padding & Stride\n",
        "   - To prevent loss of pixel information, dummy values can be added to input to side. This is typically 0.\n",
        "   - Shape of output with padding is $(w-k+1+p, h-k+1+p)$, if p = k-1, then we can have same shape for input and output (w, h)\n",
        "   - Strides are introduced to $((w-k+1+s+p)/s, (h-k+1+s+p)/s)$\n",
        "     - if p = k -1, w is divisible by s, output shape simiplifies to $(w/s, h/s)$\n",
        "     - Strides are useful for downsampling, providing different set of activations\n",
        "\n",
        "-  Convolution as matrix multiplication\n",
        "  - For input size(h, w) and kernel size k, convolution / cross correlation can be represented as matrix mulitplication using a special tobelitz matrix.\n",
        "  - Refer to [here](https://github.com/alisaaalehi/convolution_as_multiplication) for convolution can be implemented as a matrix multiplication.\n",
        "  - Shape of matrix T is $((h-k+1) * (w-k+1), (h*w))$.\n",
        "  - Convolution can be represented as matrix multiplication of T with a flattened input vector of shape $(h*w)$\n",
        "  - Cost and memory footprint is $ (h-k+1) * (w-k+1) * (h*w) $ for one input channel and one output channel.\n",
        "  - If we have $c_i$ input and $c_o$ output channels, it is $ (h-k+1) * (w-k+1) * (h*w) * c_i * c_o $\n",
        "  - Ignoring kenel size with padding and a stride of s, it simplifies to $(h^2*w^2*c_i*c_o)/s$\n",
        "\n"
      ],
      "metadata": {
        "id": "XmE0wrpf_U-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install d2l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h9s_huvjlaRy",
        "outputId": "ca5fe095-a835-4a2b-d17d-84c0a0f8193c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting d2l\n",
            "  Downloading d2l-1.0.3-py3-none-any.whl (111 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/111.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter==1.0.0 (from d2l)\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.10/dist-packages (from d2l) (1.23.5)\n",
            "Collecting matplotlib==3.7.2 (from d2l)\n",
            "  Downloading matplotlib-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib-inline==0.1.6 in /usr/local/lib/python3.10/dist-packages (from d2l) (0.1.6)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from d2l) (2.31.0)\n",
            "Collecting pandas==2.0.3 (from d2l)\n",
            "  Downloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.10.1 (from d2l)\n",
            "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (6.5.5)\n",
            "Collecting qtconsole (from jupyter==1.0.0->d2l)\n",
            "  Downloading qtconsole-5.5.1-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (6.5.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (5.5.6)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (7.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (9.4.0)\n",
            "Collecting pyparsing<3.1,>=2.3.1 (from matplotlib==3.7.2->d2l)\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (2.8.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.10/dist-packages (from matplotlib-inline==0.1.6->d2l) (5.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->d2l) (2023.4)\n",
            "Collecting tzdata>=2022.1 (from pandas==2.0.3->d2l)\n",
            "  Downloading tzdata-2023.4-py2.py3-none-any.whl (346 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.2->d2l) (1.16.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (6.3.2)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.6.6)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.0.9)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter==1.0.0->d2l) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter==1.0.0->d2l) (2.16.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.4)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (3.1.3)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (5.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (2.1.5)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.9.0)\n",
            "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (5.9.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (1.2.1)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (23.1.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.18.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.19.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.0.0)\n",
            "Collecting qtpy>=2.4.0 (from qtconsole->jupyter==1.0.0->d2l)\n",
            "  Downloading QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter==1.0.0->d2l) (4.2.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (0.2.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (4.19.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter==1.0.0->d2l) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook->jupyter==1.0.0->d2l) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter==1.0.0->d2l) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l) (0.5.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.8.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (0.17.1)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.7.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l) (1.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l) (2.21)\n",
            "Installing collected packages: tzdata, scipy, qtpy, pyparsing, jedi, pandas, matplotlib, qtconsole, jupyter, d2l\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.1\n",
            "    Uninstalling pyparsing-3.1.1:\n",
            "      Successfully uninstalled pyparsing-3.1.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed d2l-1.0.3 jedi-0.19.1 jupyter-1.0.0 matplotlib-3.7.2 pandas-2.0.3 pyparsing-3.0.9 qtconsole-5.5.1 qtpy-2.4.1 scipy-1.10.1 tzdata-2023.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from d2l import torch as d2l\n",
        "import numpy as np\n",
        "from scipy import signal"
      ],
      "metadata": {
        "id": "ITrF28ZvlT5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_2d(x, weight, bias=0, padding_type='same'):\n",
        "  \"\"\"\n",
        "    Args\n",
        "      x - (h, w)\n",
        "      weight - (k, k)\n",
        "      bias - ()\n",
        "    Returns\n",
        "      convolved output - (h-k+1, w-k+1) for padding type cut\n",
        "      convolved output - (h, w) for padding type same\n",
        "  \"\"\"\n",
        "  h, w = x.shape[0], x.shape[1]\n",
        "  k, l = weight.shape[0], weight.shape[1]\n",
        "  if padding_type == 'cut':\n",
        "    o = torch.zeros((h-k+1, w-l+1))\n",
        "  else:\n",
        "    o = torch.zeros((h, w))\n",
        "\n",
        "  k_low = int(-k/2)\n",
        "  k_high = int(k/2) + int(k%2 != 0)\n",
        "\n",
        "  l_low = int(-l/2)\n",
        "  l_high = int(l/2) + int(l%2 != 0)\n",
        "\n",
        "\n",
        "  for i in range(h):\n",
        "    for j in range(w):\n",
        "      if i + k_low >= 0 and i + k_high <= x.shape[0] and j + l_low >= 0 and j + l_high <= x.shape[1]:\n",
        "        x_hat = x[i+k_low:i+k_high, j+l_low:j+l_high]\n",
        "        if padding_type == 'same':\n",
        "          o[i, j] = (x_hat * weight).sum() + bias\n",
        "        elif padding_type == 'cut':\n",
        "          o[i+k_low, j+l_low] = (x_hat * weight).sum()\n",
        "\n",
        "\n",
        "  return o"
      ],
      "metadata": {
        "id": "zR_97SZxlsXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(([\n",
        "    [1, 2, 3, 4],\n",
        "    [4, 5, 6, 7],\n",
        "    [8, 9, 10, 11],\n",
        "    [12, 13, 14, 15]\n",
        "]))\n",
        "\n",
        "w = torch.tensor(([\n",
        "    [0, 0, 0],\n",
        "    [0, 1, 0],\n",
        "    [0, 0, 0]\n",
        "]))\n",
        "\n",
        "\n",
        "print(conv_2d(x, w, padding_type='cut'))\n",
        "print(conv_2d(x, w, padding_type='same'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7l7o-2pnaxj",
        "outputId": "c9c2e4bf-a220-42b8-ff52-7e985539728b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 5.,  6.],\n",
            "        [ 9., 10.]])\n",
            "tensor([[ 0.,  0.,  0.,  0.],\n",
            "        [ 0.,  5.,  6.,  0.],\n",
            "        [ 0.,  9., 10.,  0.],\n",
            "        [ 0.,  0.,  0.,  0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(([\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [8, 9, 10],\n",
        "]))\n",
        "\n",
        "w = torch.tensor(([\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "]))\n",
        "\n",
        "\n",
        "print(conv_2d(x, w, padding_type='cut'))\n",
        "print(conv_2d(x, w, bias=1, padding_type='same'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8JEF3manzsn",
        "outputId": "6d430b11-6906-42b5-89e2-a495054c85e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 5.,  6.],\n",
            "        [ 9., 10.]])\n",
            "tensor([[ 0.,  0.,  0.],\n",
            "        [ 0.,  6.,  7.],\n",
            "        [ 0., 10., 11.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.tensor(([\n",
        "    [0.5, 0.5],\n",
        "    [0.5, 0.5]\n",
        "]))\n",
        "\n",
        "print(conv_2d(x, w, padding_type='cut'))\n",
        "print(conv_2d(x, w, padding_type='same'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqbGx0vAwuFS",
        "outputId": "6fc27afb-b8ee-45ad-caa9-793e6b12dc96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 6.,  8.],\n",
            "        [13., 15.]])\n",
            "tensor([[ 0.,  0.,  0.],\n",
            "        [ 0.,  6.,  8.],\n",
            "        [ 0., 13., 15.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Horizontal kernels"
      ],
      "metadata": {
        "id": "3LDkGAAR9kB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.ones((5, 5))\n",
        "X[:,1:3] = 0\n",
        "k = torch.tensor([1, -1]).reshape((1, 2))\n",
        "\n",
        "print(X)\n",
        "\n",
        "conv_2d(X, k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lrGTD_z887r",
        "outputId": "2a522ba2-ebd9-4c43-f336-db2e9230d227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0., 1., 1.],\n",
            "        [1., 0., 0., 1., 1.],\n",
            "        [1., 0., 0., 1., 1.],\n",
            "        [1., 0., 0., 1., 1.],\n",
            "        [1., 0., 0., 1., 1.]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0., -1.,  0.],\n",
              "        [ 0.,  1.,  0., -1.,  0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Kernel K of shape (1, 2) can only detect horizontal edges."
      ],
      "metadata": {
        "id": "SpThSs4o_uS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.T)\n",
        "conv_2d(X.T, k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPSoj4cI88cM",
        "outputId": "109715dd-437a-4536-e777-de03e9a41057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1., 1., 1.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(k.T)\n",
        "conv_2d(X.T, k.T)"
      ],
      "metadata": {
        "id": "8SEKhOe0_6YM",
        "outputId": "885f0479-afef-476e-8145-c579f8d9c683",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1],\n",
            "        [-1]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  0.,  0.,  0.,  0.],\n",
              "        [ 1.,  1.,  1.,  1.,  1.],\n",
              "        [ 0.,  0.,  0.,  0.,  0.],\n",
              "        [-1., -1., -1., -1., -1.],\n",
              "        [ 0.,  0.,  0.,  0.,  0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn((10, 3, 100, 100))\n",
        "\n",
        "fc1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=5, padding='same', stride=1)\n",
        "\n",
        "fc1.forward(x).shape"
      ],
      "metadata": {
        "id": "Qg-wYeHRyTY1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01fb7ed0-bf38-4f17-ab19-a8a90c3ead3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 3, 100, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fc2 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=5, padding='valid', stride=2)\n",
        "fc2.forward(x).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eo2uQaSUWP9",
        "outputId": "64f97683-8f9e-4beb-e0c1-357aa3b1bd32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 3, 48, 48])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement conv2d with multiple input channels"
      ],
      "metadata": {
        "id": "Njfwf5AMVsJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def multi_input_channel_conv2d(x, weight, bias, padding_type='same'):\n",
        "    \"\"\"\n",
        "    Args\n",
        "      x - (c, h, w)\n",
        "      weight - (c, k, k)\n",
        "      bias - ()\n",
        "    Returns\n",
        "      convolved output - (h-k+1, w-k+1) for padding type cut\n",
        "      conv\n",
        "    \"\"\"\n",
        "\n",
        "    h, w = x.shape[1], x.shape[2]\n",
        "    c = x.shape[0]\n",
        "    k = weight.shape[0]\n",
        "    o = torch.zeros((h, w))\n",
        "    if padding_type == \"cut\":\n",
        "      o = torch.zeros((h-k+1, w-k+1))\n",
        "    for i in range(c):\n",
        "      o += conv_2d(x[i], weight[i], bias, padding_type)\n",
        "    return o\n",
        "\n",
        "x = torch.arange(0, 18).reshape((2, 3, 3))\n",
        "# when input has multiple channels, our conv kernel needs to have multiple channels.\n",
        "print('\\n\\nInputs\\n\\n')\n",
        "print(x[0], x[1])\n",
        "\n",
        "weight = torch.tensor((\n",
        "  [\n",
        "  [0.5, 0.5, 0.5],\n",
        "  [0.5, 0.5, 0.5],\n",
        "  [0.5, 0.5, 0.5]\n",
        "  ],\n",
        "  [\n",
        "  [0.5, 0.5, 0],\n",
        "  [0, 0, 0],\n",
        "  [0, 0, 0]\n",
        "  ]\n",
        "))\n",
        "\n",
        "print(\"\\n\\n Weight \\n\\n\")\n",
        "print(weight)\n",
        "\n",
        "print(\"\\n\\nOutput\\n\\n\")\n",
        "multi_input_channel_conv2d(x, weight, bias=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2lKWbr7Uypg",
        "outputId": "f229753c-da40-4340-adbf-ec1552afc8f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Inputs\n",
            "\n",
            "\n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]]) tensor([[ 9, 10, 11],\n",
            "        [12, 13, 14],\n",
            "        [15, 16, 17]])\n",
            "\n",
            "\n",
            " Weight \n",
            "\n",
            "\n",
            "tensor([[[0.5000, 0.5000, 0.5000],\n",
            "         [0.5000, 0.5000, 0.5000],\n",
            "         [0.5000, 0.5000, 0.5000]],\n",
            "\n",
            "        [[0.5000, 0.5000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000]]])\n",
            "\n",
            "\n",
            "Output\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000, 27.5000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_output_channel_conv2d(x, n_out, weight, bias, padding_type):\n",
        "    \"\"\"\n",
        "    Args\n",
        "      x - (c, h, w)\n",
        "      n_out - number of output channels\n",
        "      weight - (n_out, c, k, k)\n",
        "      bias - ()\n",
        "      padding_type - padding type\n",
        "    Returns\n",
        "      convolved output - (n_out, h-k+1, w-k+1) for padding type cut\n",
        "    \"\"\"\n",
        "    return torch.stack([ multi_input_channel_conv2d(x, weight[n], bias, padding_type)  for n in range(n_out)])\n",
        "\n",
        "\n",
        "x = torch.arange(0, 18).reshape((2, 3, 3))\n",
        "# when input has multiple channels, our conv kernel needs to have multiple channels.\n",
        "print('\\n\\nInputs\\n\\n')\n",
        "print(x[0], x[1])\n",
        "\n",
        "weight = torch.tensor(([\n",
        "  [\n",
        "  [0.5, 0.5, 0.5],\n",
        "  [0.5, 0.5, 0.5],\n",
        "  [0.5, 0.5, 0.5]\n",
        "  ],\n",
        "  [\n",
        "  [0.5, 0.5, 0],\n",
        "  [0, 0, 0],\n",
        "  [0, 0, 0]\n",
        "  ]],\n",
        "  [[\n",
        "  [2, 2, 2],\n",
        "  [2, 2, 2],\n",
        "  [2, 2, 2]\n",
        "  ],\n",
        "  [\n",
        "  [0.5, 0.5, 0],\n",
        "  [0, 0, 0],\n",
        "  [0, 0, 0]\n",
        "  ]]))\n",
        "\n",
        "print(\"\\n\\n Weight \\n\\n\")\n",
        "print(weight)\n",
        "\n",
        "print(\"\\n\\nOutput\\n\\n\")\n",
        "multi_output_channel_conv2d(x, 2, weight, bias=0, padding_type='same')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sD0cxbZnY5Pj",
        "outputId": "ccd6d4c2-2276-4c27-8dad-d997c2d0edb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Inputs\n",
            "\n",
            "\n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]]) tensor([[ 9, 10, 11],\n",
            "        [12, 13, 14],\n",
            "        [15, 16, 17]])\n",
            "\n",
            "\n",
            " Weight \n",
            "\n",
            "\n",
            "tensor([[[[0.5000, 0.5000, 0.5000],\n",
            "          [0.5000, 0.5000, 0.5000],\n",
            "          [0.5000, 0.5000, 0.5000]],\n",
            "\n",
            "         [[0.5000, 0.5000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[2.0000, 2.0000, 2.0000],\n",
            "          [2.0000, 2.0000, 2.0000],\n",
            "          [2.0000, 2.0000, 2.0000]],\n",
            "\n",
            "         [[0.5000, 0.5000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000]]]])\n",
            "\n",
            "\n",
            "Output\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000, 27.5000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000]],\n",
              "\n",
              "        [[ 0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000, 81.5000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000]]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = np.array([\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6]\n",
        "])\n",
        "f = np.array([\n",
        "    [10, 20],\n",
        "    [30, 40]])\n",
        "\n",
        "signal.convolve(i, np.flip(f), 'full')"
      ],
      "metadata": {
        "id": "pYW4adSVb6R1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "135d8abb-710e-412f-c4b3-d182b0ed9f4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 40, 110, 180,  90],\n",
              "       [180, 370, 470, 210],\n",
              "       [ 80, 140, 170,  60]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "47K0fB1_bg6g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}