{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajayrfhp/LearningDeepLearning/blob/main/imagenette.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whCFoMRzvsdZ"
      },
      "outputs": [],
      "source": [
        "!pip install d2l\n",
        "!pip install --upgrade torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jq3VJlzvuns"
      },
      "source": [
        "- Measure performance of LeNet and alexNet on the imagenette dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFp47skzv11d",
        "outputId": "b557b015-3030-4718-b273-9326ae9b5f0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l\n",
        "\n",
        "import torchvision\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "device_type = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "  device_type = 'cuda'\n",
        "\n",
        "device = torch.device(device_type)\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMWG8oLH1VqS"
      },
      "source": [
        "## Convert pytorch data loader into d2l data module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HwskOW01Y2s"
      },
      "outputs": [],
      "source": [
        "class ImageNette(d2l.DataModule):\n",
        "    \"\"\"ImageNette d2l module.\n",
        "\n",
        "    Defined in :numref:`sec_fashion_mnist`\"\"\"\n",
        "    def __init__(self, batch_size=128, resize=(224, 224), download=True):\n",
        "        super().__init__()\n",
        "        self.train_root = \"../train_data/\"\n",
        "        self.val_root = \"../val_data/\"\n",
        "        self.save_hyperparameters()\n",
        "        transform= transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.RandomCrop(resize),\n",
        "        transforms.ToTensor()])\n",
        "        self.train = datasets.Imagenette(root=self.train_root, split='train', download=download, transform=transform)\n",
        "        self.val = datasets.Imagenette(root=self.val_root, split='val', download=download, transform=transform)\n",
        "        self.labels = self.train.classes\n",
        "\n",
        "    def text_labels(self, indices):\n",
        "        \"\"\"Return text labels.\n",
        "\n",
        "        Defined in :numref:`sec_fashion_mnist`\"\"\"\n",
        "        return [self.labels[int(i)] for i in indices]\n",
        "\n",
        "    def get_dataloader(self, train):\n",
        "        \"\"\"Defined in :numref:`sec_fashion_mnist`\"\"\"\n",
        "        data = self.train if train else self.val\n",
        "        return torch.utils.data.DataLoader(data, self.batch_size, shuffle=train,\n",
        "                                           num_workers=self.num_workers)\n",
        "\n",
        "    def visualize(self, batch, nrows=1, ncols=8, labels=[]):\n",
        "        \"\"\"Defined in :numref:`sec_fashion_mnist`\"\"\"\n",
        "        X, y = batch\n",
        "        if not labels:\n",
        "            labels = self.text_labels(y)\n",
        "        d2l.show_images(X.squeeze(1), nrows, ncols, titles=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRj4Gqfh28Pq"
      },
      "outputs": [],
      "source": [
        "!rm -rf ../train_data/imagenette2/\n",
        "!rm -rf ../val_data/imagenette2/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3V6-96c82YPm",
        "outputId": "66aa413c-04a5-4bf2-bf3c-7358db59ca0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz to ../train_data/imagenette2.tgz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1557161267/1557161267 [00:45<00:00, 34066728.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../train_data/imagenette2.tgz to ../train_data/\n",
            "Downloading https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz to ../val_data/imagenette2.tgz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1557161267/1557161267 [00:29<00:00, 53421310.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../val_data/imagenette2.tgz to ../val_data/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.ImageNette at 0x7ce3f7c17e50>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data = ImageNette(batch_size=1028, download=True)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86d2-GpVxOun",
        "outputId": "73f0e68d-91f8-4115-da7f-4e4c28903281"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2d output shape =  torch.Size([1, 6, 224, 224]) params =  456\n",
            "ReLU output shape =  torch.Size([1, 6, 224, 224]) params =  0\n",
            "MaxPool2d output shape =  torch.Size([1, 6, 112, 112]) params =  0\n",
            "Conv2d output shape =  torch.Size([1, 6, 112, 112]) params =  906\n",
            "ReLU output shape =  torch.Size([1, 6, 112, 112]) params =  0\n",
            "MaxPool2d output shape =  torch.Size([1, 6, 56, 56]) params =  0\n",
            "Conv2d output shape =  torch.Size([1, 16, 52, 52]) params =  2416\n",
            "ReLU output shape =  torch.Size([1, 16, 52, 52]) params =  0\n",
            "MaxPool2d output shape =  torch.Size([1, 16, 26, 26]) params =  0\n",
            "Flatten output shape =  torch.Size([1, 10816]) params =  0\n",
            "Linear output shape =  torch.Size([1, 120]) params =  1298040\n",
            "ReLU output shape =  torch.Size([1, 120]) params =  0\n",
            "Linear output shape =  torch.Size([1, 84]) params =  10164\n",
            "ReLU output shape =  torch.Size([1, 84]) params =  0\n",
            "Linear output shape =  torch.Size([1, 10]) params =  850\n",
            "Total params In M =  1.312832\n"
          ]
        }
      ],
      "source": [
        "def init_cnn(module):\n",
        "    \"\"\"Initialize weights for CNNs.\"\"\"\n",
        "    if type(module) == nn.LazyLinear or type(module) == nn.Conv2d:\n",
        "        nn.init.xavier_uniform_(module.weight)\n",
        "\n",
        "class LeNetModern(d2l.Classifier):\n",
        "  def __init__(self, num_classes=10, lr=0.1):\n",
        "    super().__init__()\n",
        "    self.lr = lr\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, padding=2),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "        nn.Conv2d(in_channels=6, out_channels=6, kernel_size=5, padding=2),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "        nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "        nn.Flatten(),\n",
        "        nn.LazyLinear(120),\n",
        "        nn.ReLU(),\n",
        "        nn.LazyLinear(84),\n",
        "        nn.ReLU(),\n",
        "        nn.LazyLinear(num_classes)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)\n",
        "\n",
        "  def layer_summary(self, X_shape):\n",
        "    X = torch.randn(*X_shape)\n",
        "    total_params = 0\n",
        "    for layer in self.net:\n",
        "      X = layer(X)\n",
        "      params = sum([p.numel() for p in layer.parameters()])\n",
        "      print(layer.__class__.__name__, \"output shape = \", X.shape, \"params = \", params)\n",
        "      total_params += params\n",
        "    print(\"Total params In M = \", total_params / (1e6))\n",
        "\n",
        "\n",
        "\n",
        "modern_model = LeNetModern()\n",
        "modern_model.layer_summary((1, 3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3aV4o5Y0VhM"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_loss(model, data):\n",
        "  model.train = False\n",
        "\n",
        "  losses, access = [], []\n",
        "  for (inputs, outputs) in data.val_dataloader():\n",
        "    preds = model.forward(inputs.to(device))\n",
        "    loss = model.loss(preds, outputs.to(device)).item()\n",
        "    acc = model.accuracy(preds, outputs.to(device)).item()\n",
        "    losses.append(loss)\n",
        "    access.append(acc)\n",
        "\n",
        "  return np.mean(np.array(losses)), np.mean(np.array(access))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "EqkF6KKxyrNH",
        "outputId": "1d9448cb-dbb7-4e7c-bc14-ea562122dbab"
      },
      "outputs": [],
      "source": [
        "trainer = d2l.Trainer(max_epochs=200, num_gpus=1)\n",
        "le_net_modern = LeNetModern(lr=0.1)\n",
        "le_net_modern.apply_init([next(iter(data.get_dataloader(True)))[0]], init_cnn)\n",
        "trainer.fit(le_net_modern, data)\n",
        "get_loss(le_net_modern, data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "k9vfimc-0c7e",
        "outputId": "455835fa-3855-4c50-c84c-2304835019e1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1c0c1ead-2492-4240-9ba4-8025930f529d\", \"le_net_modern.pth\", 5255826)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import helper\n",
        "\n",
        "torch.save(le_net_modern.state_dict(), 'le_net_modern.pth')\n",
        "files.download('le_net_modern.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13XfD10A74u9",
        "outputId": "74c56542-3a01-4e7a-e358-c845a91c9fad"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Mar 13 22:10:59 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0              39W / 300W |  13952MiB / 16384MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KilBjZ70Y2J"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": [],
      "authorship_tag": "ABX9TyPTGV17Cl3ZDUJFLfd7wQ6e",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}