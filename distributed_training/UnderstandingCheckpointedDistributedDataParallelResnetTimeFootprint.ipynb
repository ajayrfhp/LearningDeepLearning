{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Checkpointed ResNet Time Footprint\n",
    "## 1. Install and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from datasets) (3.15.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from datasets) (3.11.12)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from datasets) (0.24.5)\n",
      "Requirement already satisfied: packaging in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: matplotlib in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/envs/py3.10/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install matplotlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from torch.profiler import record_function\n",
    "from datasets import load_dataset\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(710)\n",
    "np.random.seed(710)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyImageNet(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.dataset[idx][\"image\"], self.dataset[idx][\"label\"]\n",
    "        x = x.convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        y = torch.tensor(y, dtype=torch.int64)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Memory Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check baseline model memory usage\n",
    "torch.cuda.memory._record_memory_history(max_entries=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Checkpointed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "class ResnetCheckpointed(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResnetCheckpointed, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        \n",
    "        # Store individual layers\n",
    "        self.conv1 = self.model.conv1\n",
    "        self.bn1 = self.model.bn1\n",
    "        self.relu = self.model.relu\n",
    "        self.maxpool = self.model.maxpool\n",
    "        self.layer1 = self.model.layer1\n",
    "        self.layer2 = self.model.layer2\n",
    "        self.layer3 = self.model.layer3\n",
    "        self.layer4 = self.model.layer4\n",
    "        self.avgpool = self.model.avgpool\n",
    "        self.fc = self.model.fc\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply checkpointing to each layer\n",
    "        x = checkpoint(self.conv1, x)\n",
    "        x = checkpoint(self.bn1, x)\n",
    "        x = self.relu(x)  # ReLU is memory-efficient, no need to checkpoint\n",
    "        x = checkpoint(self.maxpool, x)\n",
    "        x = checkpoint(self.layer1, x)\n",
    "        x = checkpoint(self.layer2, x)\n",
    "        x = checkpoint(self.layer3, x)\n",
    "        x = checkpoint(self.layer4, x)\n",
    "        x = checkpoint(self.avgpool, x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training and Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_loader, val_loader, epochs=1, lr=0.001, break_after_num_batches=None, title=\"\"):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    total_times = []\n",
    "\n",
    "    with torch.profiler.profile(\n",
    "        activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "        schedule=torch.profiler.schedule(wait=0, warmup=0, active=6, repeat=1),\n",
    "        record_shapes=True,\n",
    "        with_stack=True,\n",
    "        profile_memory=True\n",
    "    ) as prof:\n",
    "        for epoch in range(epochs):\n",
    "            start_time = time.time()\n",
    "            for batch_idx, batch in enumerate(train_loader):\n",
    "                prof.step()\n",
    "                inputs, labels = batch\n",
    "                with record_function(\"to_device\"):\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                with record_function(\"forward\"):\n",
    "                    outputs = model(inputs)\n",
    "                with record_function(\"backward\"):\n",
    "                    criterion(outputs, labels).backward()\n",
    "                with record_function(\"optimizer_step\"):\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                end_time = time.time()\n",
    "                total_times.append(end_time - start_time)\n",
    "                if break_after_num_batches is not None and batch_idx >= break_after_num_batches:\n",
    "                    break\n",
    "                start_time = time.time()\n",
    "    prof.export_memory_timeline(f\"{title}_memory.html\", device=\"cuda:0\")\n",
    "    batch_ids = np.arange(len(total_times))\n",
    "\n",
    "    total_times = np.array(total_times)\n",
    "    mean_time = np.round(np.mean(total_times), 2)\n",
    "\n",
    "    # Plot results\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(batch_ids, total_times, label=f\"Mean time: {mean_time} s\")\n",
    "    plt.xlabel(\"Batch ID\")\n",
    "    plt.ylabel(\"Time (s)\")\n",
    "    plt.title(f\"Training performance with gradient checkpointing\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def clear_cuda_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    torch.cuda.synchronize()\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    print(f\"Allocated memory: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "    print(f\"Cached memory: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")\n",
    "\n",
    "def fit_helper(model_type, dataset, epochs, break_after_num_batches, num_workers, batch_sizes, title, device_id):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    tiny_imagenet = load_dataset(\"Maysee/tiny-imagenet\", split=\"train\")\n",
    "    tiny_imagenet_torch = TinyImageNet(tiny_imagenet, transform=transform)\n",
    "    num_classes = len(tiny_imagenet.features[\"label\"].names)\n",
    "\n",
    "    device = torch.device(f\"cuda:{device_id}\")\n",
    "    clear_cuda_memory()\n",
    "    for batch_size in batch_sizes:\n",
    "        if model_type == \"resnet18_without_checkpointing\":\n",
    "            net = models.resnet18(pretrained=True)\n",
    "        else:\n",
    "            net = ResnetCheckpointed()\n",
    "        net.to(device)\n",
    "        train_sampler = DistributedSampler(dataset, num_replicas=2, rank=device_id)\n",
    "        train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, sampler=train_sampler)\n",
    "        val_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, sampler=train_sampler)\n",
    "        oom_break = False\n",
    "        try:\n",
    "            times_dict = fit(net, train_loader, val_loader, epochs=epochs, break_after_num_batches=break_after_num_batches)\n",
    "            print(f\"Processed for batch size {batch_size}\")\n",
    "        except torch.cuda.OutOfMemoryError:\n",
    "            print(f\"Out of memory for batch size {batch_size}\")\n",
    "            oom_break = True\n",
    "        del net\n",
    "        del train_loader\n",
    "        del val_loader\n",
    "        clear_cuda_memory()\n",
    "        time.sleep(10)\n",
    "        if oom_break:\n",
    "            break\n",
    "\n",
    "def setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "\n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "def train(rank, world_size):\n",
    "    setup(rank, world_size)\n",
    "    clear_cuda_memory()\n",
    "    num_workers = 2\n",
    "    break_after_num_batches = 10\n",
    "    batch_sizes = [2500]\n",
    "    fit_helper(\n",
    "        model_type=\"resnet18_with_checkpointing\", \n",
    "        dataset=tiny_imagenet_torch, \n",
    "        epochs=1, \n",
    "        break_after_num_batches=break_after_num_batches, \n",
    "        num_workers=num_workers, \n",
    "        batch_sizes=batch_sizes,\n",
    "        title=\"with_checkpointing_2_gpus\",\n",
    "        device_id=rank\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated memory: 0.00 MB\n",
      "Cached memory: 0.00 MB\n",
      "Thu Feb 13 01:39:17 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.4     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Quadro RTX 5000                Off | 00000000:1E:00.0 Off |                  Off |\n",
      "| 34%   31C    P8              23W / 230W |    124MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro RTX 5000                Off | 00000000:3D:00.0 Off |                  Off |\n",
      "| 33%   28C    P8              13W / 230W |      8MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "clear_cuda_memory()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'train' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/root/miniconda3/envs/py3.10/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'train' on <module '__main__' (built-in)>\n",
      "W0213 01:41:06.032000 140074185762624 torch/multiprocessing/spawn.py:146] Terminating process 3722 via signal SIGTERM\n"
     ]
    },
    {
     "ename": "ProcessExitedException",
     "evalue": "process 1 terminated with exit code 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessExitedException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:282\u001b[0m, in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    276\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis method only supports start_method=spawn (got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use a different start_method use:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m torch.multiprocessing.start_processes(...)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[1;32m    281\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstart_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdaemon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspawn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:238\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:178\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ProcessExitedException(\n\u001b[1;32m    171\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with signal \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (error_index, name),\n\u001b[1;32m    172\u001b[0m             error_index\u001b[38;5;241m=\u001b[39merror_index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    175\u001b[0m             signal_name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    176\u001b[0m         )\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ProcessExitedException(\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with exit code \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (error_index, exitcode),\n\u001b[1;32m    180\u001b[0m             error_index\u001b[38;5;241m=\u001b[39merror_index,\n\u001b[1;32m    181\u001b[0m             error_pid\u001b[38;5;241m=\u001b[39mfailed_process\u001b[38;5;241m.\u001b[39mpid,\n\u001b[1;32m    182\u001b[0m             exit_code\u001b[38;5;241m=\u001b[39mexitcode,\n\u001b[1;32m    183\u001b[0m         )\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_files[error_index], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[1;32m    186\u001b[0m     original_trace \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(fh)\n",
      "\u001b[0;31mProcessExitedException\u001b[0m: process 1 terminated with exit code 1"
     ]
    }
   ],
   "source": [
    "mp.spawn(train, args=(2), nprocs=2, join=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusions\n",
    "- Checkpointing can help fit larger batch sizes with limited GPU memory.\n",
    "- This notebook explores how it impacts time and memory usage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPT2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
