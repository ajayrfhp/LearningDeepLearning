{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding ResNet Memory Footprint\n",
    "In this notebook, we explore ResNet memory usage and the effect of gradient checkpointing. The following sections demonstrate:\n",
    "- Installing required libraries\n",
    "- Loading and preparing the Tiny ImageNet dataset\n",
    "- Measuring GPU memory usage with varying batch sizes\n",
    "- Comparing results with and without gradient checkpointing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.profiler import record_function\n",
    "from datasets import load_dataset\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(710)\n",
    "np.random.seed(710)\n",
    "\n",
    "# Detect number of available CUDA devices\n",
    "print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_imagenet = load_dataset(\"Maysee/tiny-imagenet\", split=\"train\")\n",
    "print(f\"Sample record: {tiny_imagenet[0]}\")\n",
    "# Number of classes\n",
    "num_classes = len(tiny_imagenet.features[\"label\"].names)\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "class TinyImageNet(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.dataset[idx][\"image\"], self.dataset[idx][\"label\"]\n",
    "        x = x.convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        y = torch.tensor(y, dtype=torch.int64)\n",
    "        return x, y\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "tiny_imagenet_torch = TinyImageNet(tiny_imagenet, transform=transform)\n",
    "print(f\"Sample torch dataset element shape: {tiny_imagenet_torch[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory._record_memory_history(max_entries=10000)\n",
    "\n",
    "model_gpu_usage_before = torch.cuda.memory_allocated(device)\n",
    "model = models.resnet18(pretrained=True).to(device)\n",
    "model_gpu_usage_after = torch.cuda.memory_allocated(device)\n",
    "model_gpu_usage = model_gpu_usage_after - model_gpu_usage_before\n",
    "print(f\"Number of parameters in the model: {sum(p.numel() for p in model.parameters())}\")\n",
    "print(f\"Model GPU usage: {model_gpu_usage / 1024**2:.2f} MB\")\n",
    "\n",
    "del model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Memory Profiling\n",
    "The following function trains the model for a few batches while profiling memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_loader, val_loader, epochs=1, lr=0.001, break_after_num_batches=None, title=\"\"):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.profiler.profile(\n",
    "        activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "        schedule=torch.profiler.schedule(wait=0, warmup=0, active=6, repeat=1),\n",
    "        record_shapes=True,\n",
    "        with_stack=True,\n",
    "        profile_memory=True\n",
    "    ) as prof:\n",
    "        for epoch in range(epochs):\n",
    "            for batch_idx, batch in enumerate(train_loader):\n",
    "                prof.step()\n",
    "                inputs, labels = batch\n",
    "                with record_function(\"to_device\"):\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                with record_function(\"forward\"):\n",
    "                    outputs = model(inputs)\n",
    "                with record_function(\"backward\"):\n",
    "                    criterion(outputs, labels).backward()\n",
    "                with record_function(\"optimizer_step\"):\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                if break_after_num_batches is not None and batch_idx >= break_after_num_batches:\n",
    "                    break\n",
    "\n",
    "    prof.export_memory_timeline(f\"{title}_memory.html\", device=\"cuda:0\")\n",
    "\n",
    "def clear_cuda_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    torch.cuda.synchronize()\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    print(f\"Allocated memory: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "    print(f\"Cached memory: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")\n",
    "\n",
    "def fit_helper(model_type, dataset, epochs, break_after_num_batches, batch_sizes, num_workers, title):\n",
    "    for batch_size in batch_sizes:\n",
    "        if model_type == \"resnet18_without_checkpointing\":\n",
    "            model = models.resnet18(pretrained=True)\n",
    "        elif model_type == \"resnet18_with_checkpointing\":\n",
    "            model = ResnetCheckpointed()\n",
    "        model.to(device)\n",
    "        train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "        val_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "        oom_break = False\n",
    "        try:\n",
    "            fit(model, train_loader, val_loader, epochs=1, break_after_num_batches=break_after_num_batches)\n",
    "            print(f\"Processed for batch size {batch_size}\")\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Runtime error for batch size {batch_size}: {e}\")\n",
    "            oom_break = True\n",
    "        except torch.cuda.OutOfMemoryError:\n",
    "            print(f\"Out of memory for batch size {batch_size}\")\n",
    "            oom_break = True\n",
    "\n",
    "        del model\n",
    "        del train_loader\n",
    "        del val_loader\n",
    "        clear_cuda_memory()\n",
    "        time.sleep(5)\n",
    "        if oom_break:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Profiling Without Gradient Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 2\n",
    "print(f\"Number of workers: {num_workers}\")\n",
    "break_after_num_batches = 10\n",
    "batch_sizes = [128, 256, 512, 1024, 2048, 4096, 8192]\n",
    "\n",
    "fit_helper(\"resnet18_without_checkpointing\", tiny_imagenet_torch, 1, break_after_num_batches, batch_sizes, num_workers, title=\"without_checkpointing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model with Gradient Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.checkpoint import checkpoint\n",
    "import torchvision.models as models\n",
    "\n",
    "class ResnetCheckpointed(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResnetCheckpointed, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        \n",
    "        # Store individual layers\n",
    "        self.conv1 = self.model.conv1\n",
    "        self.bn1 = self.model.bn1\n",
    "        self.relu = self.model.relu\n",
    "        self.maxpool = self.model.maxpool\n",
    "        self.layer1 = self.model.layer1\n",
    "        self.layer2 = self.model.layer2\n",
    "        self.layer3 = self.model.layer3\n",
    "        self.layer4 = self.model.layer4\n",
    "        self.avgpool = self.model.avgpool\n",
    "        self.fc = self.model.fc\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply checkpointing to each layer\n",
    "        x = checkpoint(self.conv1, x)\n",
    "        x = checkpoint(self.bn1, x)\n",
    "        x = self.relu(x)  # ReLU is memory-efficient, no need to checkpoint\n",
    "        x = checkpoint(self.maxpool, x)\n",
    "        x = checkpoint(self.layer1, x)\n",
    "        x = checkpoint(self.layer2, x)\n",
    "        x = checkpoint(self.layer3, x)\n",
    "        x = checkpoint(self.layer4, x)\n",
    "        x = checkpoint(self.avgpool, x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Profiling With Gradient Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_helper(\"resnet18_with_checkpointing\", tiny_imagenet_torch, 1, break_after_num_batches, batch_sizes, num_workers, title=\"with_checkpointing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "- Without gradient checkpointing, we were able to fit up to a batch size of 1024 (before running out of memory).\n",
    "- With gradient checkpointing, we could fit larger batch sizes (up to 4096) in the same GPU.\n",
    "\n",
    "For memory-intensive tasks, gradient checkpointing can be a useful technique to trade compute for memory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPT2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
